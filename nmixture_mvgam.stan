// Stan model code generated by package mvgam
functions {
  /* Functions to return the log probability of a Poisson Binomial Mixture */
    
    /* see Bollen et al 2023 for details (https://doi.org/10.1002/ece3.10595)*/
    real poisbin_lpmf(array[] int count, int k, array[] real lambda, array[] real p) {
    if (max(count) > k) {
      return negative_infinity();
    }
      return poisson_log_lpmf(k | lambda) + binomial_logit_lpmf(count | k, p);
    }
  vector pb_logp(array[] int count, int max_k, array[] real lambda, array[] real p) {
    int c_max = max(count);
    if (max_k < c_max) {
      reject("cap variable max_k must be >= observed counts");
    }

    vector[max_k + 1] lp;
    for (k in 0 : (c_max - 1))
      lp[k + 1] = negative_infinity();
    for (k in c_max : max_k) 
      lp[k + 1] = poisbin_lpmf(count| k, lambda, p);
    return lp;
  }
  real pb_lpmf(array[] int count, array[] int max_k, array[] real lambda, array[] real p) {
    // Take maximum of all supplied caps, in case they vary for some reason
    int max_k_max = max(max_k);
    vector[max_k_max + 1] lp;
    lp = pb_logp(count, max_k_max, lambda, p);
    return log_sum_exp(lp);
  }
  /* Functions to generate truncated Poisson variates */
    int nmix_rng(int count, int max_k, real lambda, real p) {
      array[1] int count_array;
      count_array[1] = count;
      array[1] real lambda_array;
      lambda_array[1] = lambda;
      array[1] real p_array;
      p_array[1] = p;
      vector[max_k + 1] lp;
      lp = pb_logp(count_array, max_k, lambda_array, p_array);
      return categorical_rng(softmax(lp)) - 1;
    }
  int trunc_pois_rng(int max_k, real lambda) {
    real p_ub = poisson_cdf(max_k | lambda);
    if (p_ub < 1e-9) {
      return max_k;
    }
    real u = uniform_rng(0, p_ub);
    int i = 0;
    int X = 0;
    real p = exp(-lambda);
    real F = p;
    while (1) {
      if (u < F) {
        X = i;
        break;
      }
      i = i + 1;
      p = lambda * p / i;
      F = F + p;
    }
    return X;
  }
}
data {
  int<lower=0> total_obs; // total number of observations
  int<lower=0> n; // number of timepoints per series
  int<lower=0> n_lv; // number of dynamic factors
  int<lower=0> n_sp; // number of smoothing parameters
  int<lower=0> n_sp_trend; // number of trend smoothing parameters
  int<lower=0> n_series; // number of series
  matrix[n_series, n_lv] Z; // matrix mapping series to latent states
  int<lower=0> num_basis; // total number of basis coefficients
  int<lower=0> num_basis_trend; // number of trend basis coefficients
  vector[num_basis_trend] zero_trend; // prior locations for trend basis coefficients
  vector[num_basis] zero; // prior locations for basis coefficients
  matrix[total_obs, num_basis] X; // mgcv GAM design matrix
  matrix[n * n_lv, num_basis_trend] X_trend; // trend model design matrix
  array[n, n_series] int<lower=0> ytimes; // time-ordered matrix (which col in X belongs to each [time, series] observation?)
  array[n, n_lv] int ytimes_trend;
  matrix[9, 18] S1; // mgcv smooth penalty matrix S1
  int<lower=0> n_nonmissing; // number of nonmissing observations
  array[total_obs] int<lower=0> cap; // upper limits of latent abundances
  matrix[3, 6] S_trend1; // mgcv smooth penalty matrix S_trend1
  array[n_nonmissing] int<lower=0> flat_ys; // flattened nonmissing observations
  matrix[n_nonmissing, num_basis] flat_xs; // X values for nonmissing observations
  array[n_nonmissing] int<lower=0> obs_ind; // indices of nonmissing observations
 
  // new 
  int<lower=0> K_groups; // number of unique replicated observations
  int<lower=1> n_replicates; // number of replicated observations per timepoint
  array[K_groups, n_replicates] int K_inds; // groups for replicate, nonmissing observations
}
transformed data {
  
}
parameters {
  // raw basis coefficients
  vector[num_basis] b_raw;
  vector[num_basis_trend] b_raw_trend;
  
  // smoothing parameters
  vector<lower=0>[n_sp] lambda;
  vector<lower=0>[n_sp_trend] lambda_trend;
}
transformed parameters {
  // detection probability
  vector[total_obs] p;
  
  // latent states
  matrix[n, n_lv] LV;
  
  // latent states and loading matrix
  vector[n * n_lv] trend_mus;
  matrix[n, n_series] trend;
  matrix[n_series, n_lv] lv_coefs;
  
  // basis coefficients
  vector[num_basis] b;
  vector[num_basis_trend] b_trend;
  
  // observation model basis coefficients
  b[1 : num_basis] = b_raw[1 : num_basis];
  
  // process model basis coefficients
  b_trend[1 : num_basis_trend] = b_raw_trend[1 : num_basis_trend];
  
  // detection probability
  p = X * b;
  
  // latent process linear predictors
  trend_mus = X_trend * b_trend;
  for (j in 1 : n_lv) {
    LV[1 : n, j] = trend_mus[ytimes_trend[1 : n, j]];
  }
  
  // derived latent states
  lv_coefs = Z;
  for (i in 1 : n) {
    for (s in 1 : n_series) {
      trend[i, s] = dot_product(lv_coefs[s,  : ], LV[i,  : ]);
    }
  }
}
model {
  // prior for s(rainfall)...
  b_raw[1 : 9] ~ multi_normal_prec(zero[1 : 9],
                                   S1[1 : 9, 1 : 9] * lambda[1]
                                   + S1[1 : 9, 10 : 18] * lambda[2]);
  
  // priors for smoothing parameters
  lambda ~ normal(5, 30);
  
  // dynamic process models
  
  // prior for (Intercept)_trend...
  b_raw_trend[1] ~ normal(2, 2);
  
  // prior for s(temperature)_trend...
  b_raw_trend[2 : 4] ~ multi_normal_prec(zero_trend[2 : 4],
                                         S_trend1[1 : 3, 1 : 3]
                                         * lambda_trend[1]
                                         + S_trend1[1 : 3, 4 : 6]
                                         * lambda_trend[2]);
  lambda_trend ~ normal(5, 30);
  {
    // likelihood functions
    vector[n_nonmissing] flat_trends;
    vector[n_nonmissing] flat_ps;
    array[n_nonmissing] int flat_caps;
    flat_trends = to_vector(trend)[obs_ind];
    flat_ps = p[obs_ind];
    flat_caps = cap[obs_ind];
    for (k in 1:K_groups) {
      target += pb_lpmf(flat_ys[K_inds[k]] | 
                        flat_caps[K_inds[k]],
                        to_array_1d(flat_trends[K_inds[k]]), 
                        to_array_1d(flat_ps[K_inds[k]]));
    }
  }
}
generated quantities {
  vector[total_obs] eta;
  matrix[n, n_series] mus;
  vector[n_sp] rho;
  vector[n_sp_trend] rho_trend;
  vector[n_lv] penalty;
  array[n, n_series] int ypred;
  array[n, n_series] int latent_ypred;
  array[total_obs] int latent_truncpred;
  vector[n_nonmissing] flat_ps;
  array[n_nonmissing] int flat_caps;
  vector[total_obs] flat_trends;
  vector[n_nonmissing] flat_trends_nonmis;
  vector[total_obs] detprob;
  detprob = inv_logit(p);
  rho = log(lambda);
  rho_trend = log(lambda_trend);
  penalty = rep_vector(1e12, n_lv);
  
  // posterior predictions
  eta = X * b;
  {
    flat_trends = to_vector(trend);
    flat_trends_nonmis = flat_trends[obs_ind];
    flat_ps = p[obs_ind];
    flat_caps = cap[obs_ind];
    
    // prediction for all timepoints that ignore detection prob
    for (i in 1 : total_obs) {
      latent_truncpred[i] = trunc_pois_rng(cap[i], exp(flat_trends[i]));
    }
    
    // prediction for the nonmissing timepoints using actual obs
    for (i in 1 : n_nonmissing) {
      latent_truncpred[obs_ind[i]] = nmix_rng(flat_ys[i], flat_caps[i],
                                              flat_trends_nonmis[i],
                                              flat_ps[i]);
    }
    for (s in 1 : n_series) {
      // true latent abundance
      latent_ypred[1 : n, s] = latent_truncpred[ytimes[1 : n, s]];
      
      // observed abundance
      ypred[1 : n, s] = binomial_rng(latent_ypred[1 : n, s],
                                     detprob[ytimes[1 : n, s]]);
      
      // expected values
      for (i in 1 : n) {
        mus[i, s] = detprob[ytimes[i, s]] * latent_ypred[i, s];
      }
    }
  }
}
